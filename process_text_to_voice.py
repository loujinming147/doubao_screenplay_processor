#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤„ç†æ–‡ä»¶çš„ä¸»è„šæœ¬
ç”ŸæˆéŸ³é¢‘ï¼Œåˆå¹¶ä¸ºå®Œæ•´çš„æ’­å®¢
"""

import asyncio
import os
import sys

from utils import ToNlpTexts, merge_audio_files
from bidirection_client import BidirectionTTSClient
import time
import argparse
import logging
from pathlib import Path

def setup_logger(log_dir: str = "logs") -> logging.Logger:
    """è®¾ç½®æ—¥å¿—ï¼šåŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°å’Œæ–‡ä»¶"""
    os.makedirs(log_dir, exist_ok=True)
    log_file = os.path.join(log_dir, f"podcast_{time.strftime('%Y%m%d')}.log")

    logger = logging.getLogger("PodcastGenerator")
    logger.setLevel(logging.INFO)

    # é¿å…é‡å¤æ·»åŠ  handler
    if logger.handlers:
        return logger

    # æ–‡ä»¶å¤„ç†å™¨
    file_handler = logging.FileHandler(log_file, encoding='utf-8')
    file_handler.setLevel(logging.INFO)

    # æ§åˆ¶å°å¤„ç†å™¨
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.INFO)

    # æ—¥å¿—æ ¼å¼
    formatter = logging.Formatter(
        '[%(asctime)s] %(levelname)s: %(message)s',
        datefmt='%Y-%m-%d %H:%M:%S'
    )
    file_handler.setFormatter(formatter)
    console_handler.setFormatter(formatter)

    logger.addHandler(file_handler)
    logger.addHandler(console_handler)
    return logger


async def main(args):
    logger = setup_logger()

    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("æ’­å®¢éŸ³é¢‘ç”Ÿæˆå™¨")
    print("=" * 60)
    
    # è®¾ç½®è¯­éŸ³æ˜ å°„ - å°†ä¸ç™½åƒå’Œè‹è½¼éƒ½è®¾ç½®ä¸ºS_62w7if2J1
    print("ğŸ“ é…ç½®è¯­éŸ³æ˜ å°„...")


    print("âœ… è¯­éŸ³æ˜ å°„é…ç½®å®Œæˆ:")
    for speaker, voice in args.voice_mapping.items():
        print(f"   {speaker} -> {voice}")
    
    # æ–‡ä»¶è·¯å¾„é…ç½®
    text_file = args.text_file
    # output_dir = args.output_dir
    filename = os.path.basename(text_file)
    stem = Path(filename).stem
    output_dir = os.path.join(args.output_dir, stem)
    os.makedirs(output_dir, exist_ok=True)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(text_file):
        print(f"âŒ é”™è¯¯: TEXTæ–‡ä»¶ä¸å­˜åœ¨: {text_file}")
        return
    
    print(f"\nğŸ“‚ è¾“å…¥æ–‡ä»¶: {text_file}")
    print(f"ğŸ“ è¾“å‡ºç›®å½•: {output_dir}")
    
    try:
        # å¼€å§‹å¤„ç†
        print(f"\nğŸš€ å¼€å§‹å¤„ç†æ–‡ä»¶...")
  
        # ä½¿ç”¨åŒå‘åè®®ç”ŸæˆéŸ³é¢‘ï¼ˆæ”¯æŒ Resource åˆ‡æ¢ï¼‰
        use_bidirection = True
        if use_bidirection:

            # è§£ææ–‡æœ¬ä¸ºæ®µè½
            converter = ToNlpTexts()
            converter.voice_mapping.update(args.voice_mapping)
            nlp_texts = converter.convert_file_to_nlp_texts(text_file)
            print(f"è§£æå®Œæˆï¼Œå…± {len(nlp_texts)} ä¸ªæ–‡æœ¬æ®µè½")
        
            # åŒå‘å®¢æˆ·ç«¯
            client = BidirectionTTSClient(
                appid=args.appid,
                access_token=args.access_token,
            )
        
            os.makedirs(output_dir, exist_ok=True)
            audio_files = []
        
        
            for i, item in enumerate(nlp_texts):
                text = item["text"]
                voice_type = item["speaker"]  # å·²æ˜¯ voice_idï¼Œä¾‹å¦‚ S_62w7if2J1
                # é€‰æ‹©èµ„æºIDï¼šS_ å‰ç¼€é»˜è®¤ seed-tts-2.0ï¼›å¦åˆ™ seed-icl-2.0ï¼›ä¹Ÿå¯ç”¨ icl_voices å¼ºåˆ¶å¤åˆ»
                resource_id = (
                    "seed-tts-2.0"
                    if not voice_type.startswith("S_")
                    else "seed-icl-2.0"
                )
                output_file = os.path.join(
                    output_dir, f"segment_{i:03d}_{voice_type}.mp3"
                )
                print(f"æ­£åœ¨ç”ŸæˆéŸ³é¢‘: {output_file} | voice={voice_type} | resource={resource_id}")
                print(f"æ–‡æœ¬å†…å®¹: {text}")
                # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨åˆ™è·³è¿‡
                # if os.path.exists(output_file) and voice_type != "zh_male_taocheng_uranus_bigtts":
                if os.path.exists(output_file):
                    print(f"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {output_file}")
                    audio_files.append(output_file)
                    continue        
                ##########################################
                #### æ‰‹åŠ¨ä¿®æ”¹éŸ³é¢‘å‚æ•° ######################
                ##########################################
                if voice_type == "S_7ndFaTPI1":
                    speech_rate = 0
                    loudness_rate = 10
                    emotion = "neutral"
                    emotion_scale = 0
                    pitch_rate = 0
                elif voice_type == "zh_male_taocheng_uranus_bigtts":
                    speech_rate = 0
                    loudness_rate = 0
                    emotion = "neutral"
                    emotion_scale = 0
                    pitch_rate = 5
                elif voice_type == "S_7ndFaTPI1":
                    speech_rate = 10
                    loudness_rate = 0
                    emotion = "neutral"
                    emotion_scale = 0
                    pitch_rate = 0
                elif voice_type == "saturn_zh_female_tiaopigongzhu_tob":
                    speech_rate = 0
                    loudness_rate = 0
                    emotion = "neutral"
                    emotion_scale = 0
                    pitch_rate = 4
                elif voice_type == "S_vJMEaTPI1":
                    speech_rate = 20
                    loudness_rate = 0
                    emotion = "neutral"
                    emotion_scale = 0
                    pitch_rate = 0
                else:
                    speech_rate=args.speech_rate
                    loudness_rate=args.loudness_rate
                    emotion=args.emotion
                    emotion_scale=args.emotion_scale
                    pitch_rate = args.pitch_rate
                try:
                    logger.info(f"   ğŸ™ï¸ ç”Ÿæˆæ®µè½ {i+1}/{len(nlp_texts)} | voice={voice_type}")
                    print("text:", text)
                    await client.synthesize_to_file(
                    text=text,
                    voice_type=voice_type,
                    resource_id=resource_id,
                    output_file=output_file,
                    encoding="mp3",
                    speech_rate=speech_rate,
                    loudness_rate=loudness_rate,
                    emotion=emotion,
                    emotion_scale=emotion_scale,
                    pitch_rate=pitch_rate,
                    )
                    audio_files.append(output_file)
                except Exception as e:
                    logger.error(f"âŒ TTS ç”Ÿæˆå¤±è´¥ (æ®µè½ {i}): {e}")
                    continue  # ç»§ç»­å¤„ç†åç»­æ®µè½
        
            # åˆå¹¶æ®µè½ä¸ºå®Œæ•´æ’­å®¢ï¼Œå¤ç”¨ä½ å·²æœ‰å‡½æ•°
            final_audio = os.path.join(
                output_dir, f"podcast_complete_{int(time.time())}.mp3"
            )
            ok = merge_audio_files(audio_files, final_audio)
            if not ok:
                raise RuntimeError("éŸ³é¢‘åˆå¹¶å¤±è´¥")
        
            print(f"\nğŸ‰ å¤„ç†å®Œæˆ!")
            print(f"ğŸµ æœ€ç»ˆéŸ³é¢‘æ–‡ä»¶: {final_audio}")
            if os.path.exists(final_audio):
                file_size = os.path.getsize(final_audio)
                print(f"ğŸ“Š æ–‡ä»¶å¤§å°: {file_size / 1024 / 1024:.2f} MB")
            return
        
        print(f"\nğŸ’¡ æç¤º:")
        print(f"   - æ‰€æœ‰éŸ³é¢‘æ®µè½éƒ½ä½¿ç”¨ S_62w7if2J1 è¯­éŸ³ç±»å‹")
        print(f"   - ä¸ªåˆ«éŸ³é¢‘æ–‡ä»¶ä¿å­˜åœ¨: {output_dir}")
        print(f"   - åˆå¹¶åçš„å®Œæ•´éŸ³é¢‘: {final_audio}")
        
    except Exception as e:
        print(f"\nâŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
def parse_args():
    parser = argparse.ArgumentParser(description="å¤„ç†æ–‡æœ¬æ–‡ä»¶ç”Ÿæˆè¯­éŸ³æ’­å®¢")
    parser.add_argument("--text_file", type=str, default="assets/ä¸ç™½åƒç§‘æ™®å¨ƒå¨ƒæ–‡ç¨¿éƒ¨åˆ†.docx", help="è¾“å…¥çš„ TEXT æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output_dir", type=str, default="output/kepuwawa", help="è¾“å‡ºç›®å½•è·¯å¾„")
    parser.add_argument("--appid", type=str, default="7913609641", help="Doubao åº”ç”¨ ID")
    parser.add_argument("--access_token", type=str, default="teLzt62B8gRhfKVOqAbEpiCgDl1Jxcjq", help="Doubao è®¿é—®ä»¤ç‰Œ")
    parser.add_argument("--speech_rate", type=int, default=0, help="è¯­é€Ÿè°ƒæ•´å‚æ•° -50,100 é»˜è®¤0ä¸ä½¿ç”¨è¯­é€Ÿè°ƒæ•´")
    parser.add_argument("--loudness_rate", type=int, default=0, help="éŸ³é‡è°ƒæ•´å‚æ•° -50,100 é»˜è®¤0ä¸ä½¿ç”¨éŸ³é‡è°ƒæ•´")
    parser.add_argument("--emotion", type=str, default="neutral", help="æƒ…æ„Ÿè°ƒæ•´å‚æ•°  é»˜è®¤neutralä¸ä½¿ç”¨")
    parser.add_argument("--emotion_scale", type=float, default=0, help="æƒ…æ„Ÿå¼ºåº¦è°ƒæ•´å‚æ•° 1-5 é»˜è®¤0ä¸ä½¿ç”¨æƒ…æ„Ÿè°ƒæ•´")
    parser.add_argument("--pitch_rate", type=int, default=0, help="éŸ³è°ƒè°ƒæ•´å‚æ•° -50,100 é»˜è®¤0ä¸ä½¿ç”¨éŸ³è°ƒè°ƒæ•´")

    return parser.parse_args()

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯"""
    print("=" * 40)
    print("åŠŸèƒ½:")
    print("  - è¯»å– TEXT æ–‡ä»¶")
    print("  - è§£æå¯¹è¯å†…å®¹")
    print("  - ä½¿ç”¨ S_62w7if2J1 è¯­éŸ³ç±»å‹ç”ŸæˆéŸ³é¢‘")
    print("  - åˆå¹¶æ‰€æœ‰éŸ³é¢‘æ®µè½ä¸ºå®Œæ•´æ’­å®¢")
    print()
    print("ç”¨æ³•:")
    print("  python process_text_to_voice.py")
    print("  python process_text_to_voice.py --help")

if __name__ == "__main__":
    
    args = parse_args()
    voice_mapping = {
        "ä¸ç™½åƒ": "S_fN2KaTPI1",
        "å¤§æ–¹è„¸": "zh_male_taocheng_uranus_bigtts", # pitch_rate = 5
        "å° A": "S_7ndFaTPI1", # speech_rate = 10
        "è“è¡€è±†": "saturn_zh_female_tiaopigongzhu_tob",  # pitch_rate = 4
        "è¯èœ‚å©†å©†": "S_vJMEaTPI1", # speech_rate = 30
    }
        # voice_mapping = {
    #     "ä¸ç™½åƒ": "S_fN2KaTPI1",
    #     # "å¼ éª": "saturn_zh_female_tiaopigongzhu_tob",
    #     # "æœ±å…ƒç’‹": "S_vNQFaTPI1"
    #     "é£Ÿå®¢B": "S_hUnLaTPI1",
    #     "é£Ÿå®¢A": "S_vNQFaTPI1",
    #     "æ­¦åˆ™å¤©": "S_vJMEaTPI1",
    #     "ä¸Šå®˜å©‰å„¿": "zh_female_meilinvyou_saturn_bigtts",
    #     "ä¾å«": "zh_male_taocheng_uranus_bigtts"
    # }

    args.voice_mapping = voice_mapping
    
    asyncio.run(main(args))
